{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69iMR19PL0Lu"
      },
      "source": [
        "## Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h3xNFIdL0Ly",
        "outputId": "260ed649-7886-41ca-e723-422de6479960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import nltk\n",
        "import itertools\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjUhZ0whL0L0"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h30ub96YL0L1"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "with open('tweets.json') as jfile:\n",
        "    d = json.load(jfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WJxeNSD9L0L2"
      },
      "outputs": [],
      "source": [
        "# create pandas dataframe\n",
        "tweet_id=[]\n",
        "tweet_author=[]\n",
        "tweet_text=[]\n",
        "for key,values in d.items():\n",
        "    tweet_id.append(key)\n",
        "    for keys,val in values.items():\n",
        "        if keys=='tweet_author':\n",
        "            tweet_author.append(val)\n",
        "        if keys=='tweet_text':\n",
        "            tweet_text.append(val)\n",
        "tweets=np.hstack((np.array(tweet_id).reshape(-1,1),np.array(tweet_author).reshape(-1,1),np.array(tweet_text).reshape(-1,1)))\n",
        "data_df=pd.DataFrame(tweets,columns=['tweet_ID','tweet_author','tweet_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GFDCFLIUL0L3",
        "outputId": "a9b712e2-3f7e-43ff-c489-2c06fd860d13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-64f25527-0c05-4c6a-91a6-f6c82f213795\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_ID</th>\n",
              "      <th>tweet_author</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1374140386071961602</td>\n",
              "      <td>Hematopoiesis News</td>\n",
              "      <td>‚öïÔ∏è Scientists conducted a Phase II study of ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1374032432173842437</td>\n",
              "      <td>Michael Wang, MD</td>\n",
              "      <td>This phase 2 Acalabrutinib-Venetoclax (AV) tri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1373902876553048065</td>\n",
              "      <td>1stOncology</td>\n",
              "      <td>#NICE backs #AstraZenecas #Calquence for #CLL ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1373656782367813635</td>\n",
              "      <td>Toby Eyre</td>\n",
              "      <td>#acalabrutinib is a valuable option in pts int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1372941634334232586</td>\n",
              "      <td>Lymphoma Hub</td>\n",
              "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64f25527-0c05-4c6a-91a6-f6c82f213795')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64f25527-0c05-4c6a-91a6-f6c82f213795 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64f25527-0c05-4c6a-91a6-f6c82f213795');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              tweet_ID        tweet_author  \\\n",
              "0  1374140386071961602  Hematopoiesis News   \n",
              "1  1374032432173842437    Michael Wang, MD   \n",
              "2  1373902876553048065         1stOncology   \n",
              "3  1373656782367813635           Toby Eyre   \n",
              "4  1372941634334232586        Lymphoma Hub   \n",
              "\n",
              "                                          tweet_text  \n",
              "0  ‚öïÔ∏è Scientists conducted a Phase II study of ac...  \n",
              "1  This phase 2 Acalabrutinib-Venetoclax (AV) tri...  \n",
              "2  #NICE backs #AstraZenecas #Calquence for #CLL ...  \n",
              "3  #acalabrutinib is a valuable option in pts int...  \n",
              "4  NICE has recommended the use of acalabrutinib ...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV6_NtlpL0L5",
        "outputId": "8210396a-85cb-4a08-c04d-e9639229314d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Patient Power            1603\n",
              "Paperbirds_Hematology    1510\n",
              "VJHemOnc                 1079\n",
              "Oncology Tube             714\n",
              "Medivizor                 663\n",
              "                         ... \n",
              "Streetwise Reports          1\n",
              "Onco.com                    1\n",
              "Investor's Champion         1\n",
              "21                          1\n",
              "ùìíùìªùì≤ùîÉùîÉùîÇ ùìüùìÆùìªùìªùîÇüåπ               1\n",
              "Name: tweet_author, Length: 9292, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df['tweet_author'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uRKNL7QKn5Ij"
      },
      "outputs": [],
      "source": [
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wILin9GqdNy-"
      },
      "outputs": [],
      "source": [
        "pre_processed_tweets=[]\n",
        "for i in data_df['tweet_text']:\n",
        "  text = re.sub(r\"\\S*https?:\\S*\", \"\", i) \n",
        "  text = re.sub('[.,-]','',text)\n",
        "  text = re.sub(r\"[\\([{})|:*!?\\]]\", \"\", text)\n",
        "  text = re.sub(r\"[\\/'';\" \"\\]]\", \" \", text)\n",
        "  text = decontracted(text)\n",
        "  text = text.replace(\"‚Äôs\", \"\")\n",
        "  text = text.replace(\"¬Æ\", \"\")\n",
        "  text = text.replace(\"New article:\", \"\")\n",
        "  text = text.replace(\"new\", \"\")\n",
        "  text = text.replace(\"Link:\", \"\")\n",
        "  text=re.sub(\"[\\\"\\']\", \"\", text)\n",
        "  text=re.sub(\"[\\\\n\\']\", \"\", text)\n",
        "  # remove foreign launguage tweets\n",
        "  res = [idx for idx in text if not re.findall(\"[^\\u0000-\\u05C0\\u2100-\\u214F]+\", idx)]\n",
        "  text=''.join(res)\n",
        "  text=re.sub(\"[\\\\n\\']\", \"\", text)\n",
        "  text = decontracted(text)\n",
        "  text=text.strip()\n",
        "  text=re.sub(r'[0-9]+', '', text)\n",
        "  pre_processed_tweets.append(text)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wb86jBClMkRZ"
      },
      "outputs": [],
      "source": [
        "data_df['tweet_text']=pre_processed_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xnT_KoudL0L8"
      },
      "outputs": [],
      "source": [
        "values=[]\n",
        "keys=list(set(data_df['tweet_author'].values))\n",
        "for i in range(len(keys)):\n",
        "    values.append([])\n",
        "dictt=dict(zip(keys,values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fful7xaT09nc"
      },
      "source": [
        "## TASK -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SBxsfyq0L0L8"
      },
      "outputs": [],
      "source": [
        "# create pos tags to each tweet and combine simillar \n",
        "# parts of speech words that are contigous as a single entity\n",
        "for i in range(len(data_df)):\n",
        "    key=data_df['tweet_author'][i]\n",
        "    a=nltk.tag.pos_tag(data_df['tweet_text'][i].split())\n",
        "    for index,i in enumerate(a):\n",
        "        if i[0][0]=='#' or i[0][0]=='@':\n",
        "          dictt[key].append(i[0][1:])\n",
        "        elif index==0:\n",
        "            dictt[key].append(i[0])\n",
        "            prev=i[1]\n",
        "        elif i[1]==prev:\n",
        "            dictt[key][-1]=dictt[key][-1]+' '+i[0]\n",
        "            prev=i[1]\n",
        "        else:\n",
        "            dictt[key].append(i[0])\n",
        "            prev=i[1]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dqj9rwjBN2H6"
      },
      "outputs": [],
      "source": [
        "for key,value in dictt.items():\n",
        "  filtered_sentence = [w.lower() for w in value if not w.lower() in stop_words and len(w)>2]\n",
        "  dictt[key]=filtered_sentence\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q1sN09soL0L9"
      },
      "outputs": [],
      "source": [
        "# To remove repeated words from all tweets by a given author\n",
        "keys=list(dictt.keys())\n",
        "for key in keys:\n",
        "    dictt[key]=list(set(dictt[key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RKc4Es8ML0L-"
      },
      "outputs": [],
      "source": [
        "word_corpus=list(itertools.chain.from_iterable(list(dictt.values())))\n",
        "word_corpus_df=pd.DataFrame(word_corpus,columns=['words'])\n",
        "frequency_of_words=word_corpus_df['words'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FJE7yGYL2Tj6"
      },
      "outputs": [],
      "source": [
        "objective1 = frequency_of_words.reset_index()\n",
        "objective1.columns = ['entity', 'frequency']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "cYaBfVfW2r_Z"
      },
      "outputs": [],
      "source": [
        "objective1.to_csv('objective1.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "wmf6UtNu24zp",
        "outputId": "40f617af-c391-4de0-b3c1-0e4e79527913"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-42281124-1de5-48d9-b950-5ec53b6115d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cll</td>\n",
              "      <td>3364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>leukemia</td>\n",
              "      <td>3081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chronic lymphocytic</td>\n",
              "      <td>2615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patients</td>\n",
              "      <td>2045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>acalabrutinib</td>\n",
              "      <td>1416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>treatment</td>\n",
              "      <td>1069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>chronic lymphocytic leukemia</td>\n",
              "      <td>1033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ibrutinib</td>\n",
              "      <td>789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cancer</td>\n",
              "      <td>758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>calquence</td>\n",
              "      <td>709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>lymphoma</td>\n",
              "      <td>704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>chronic</td>\n",
              "      <td>680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>venetoclax</td>\n",
              "      <td>671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>lymphocytic</td>\n",
              "      <td>654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>relapsed</td>\n",
              "      <td>646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>covid</td>\n",
              "      <td>614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>fda</td>\n",
              "      <td>596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>astrazeneca</td>\n",
              "      <td>528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42281124-1de5-48d9-b950-5ec53b6115d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-42281124-1de5-48d9-b950-5ec53b6115d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-42281124-1de5-48d9-b950-5ec53b6115d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          entity  frequency\n",
              "0                            cll       3364\n",
              "1                       leukemia       3081\n",
              "2            chronic lymphocytic       2615\n",
              "3                       patients       2045\n",
              "4                  acalabrutinib       1416\n",
              "5                      treatment       1069\n",
              "6   chronic lymphocytic leukemia       1033\n",
              "7                      ibrutinib        789\n",
              "8                         cancer        758\n",
              "9                      calquence        709\n",
              "10                      lymphoma        704\n",
              "11                       chronic        680\n",
              "12                    venetoclax        671\n",
              "13                   lymphocytic        654\n",
              "14                      relapsed        646\n",
              "15                         covid        614\n",
              "16                           fda        596\n",
              "17                   astrazeneca        528"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "objective1[:18]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CuPhQNeAH_x"
      },
      "source": [
        "## TASK 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrv9pVl0AKdY",
        "outputId": "fe24572e-2ad6-4ece-877d-dadb6c647c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.7 MB 9.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 58.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120 kB 80.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R0bYOPczFcFs"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM,Flatten\n",
        "import datetime\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "from transformers import  DistilBertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1jgI9H6_nko",
        "outputId": "9d513aed-dfba-4bdf-bcdb-51dbc88381ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_transform', 'activation_13', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "distil_bert = 'distilbert-base-uncased' # Name of the pretrained models\n",
        "\n",
        "config = DistilBertConfig.from_pretrained(distil_bert, output_hidden_states=True)\n",
        "#DistilBERT \n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert)\n",
        "\n",
        "model = TFDistilBertModel.from_pretrained(distil_bert, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5KaIV6eLCKO",
        "outputId": "814040d8-f686-4da6-ab7d-62918355bfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/tweet_dataset.csv.zip\n",
            "  inflating: tweet_dataset.csv       \n"
          ]
        }
      ],
      "source": [
        "! unzip /content/tweet_dataset.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Twitter sentiment analysis dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4FnynsxMSiKj"
      },
      "outputs": [],
      "source": [
        "df_general_tweets=pd.read_csv('/content/tweet_dataset.csv.zip')\n",
        "df_train=df_general_tweets[['text','new_sentiment']]\n",
        "df_train=df_train.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rf22Hg0XbskS"
      },
      "outputs": [],
      "source": [
        "processed_tweets=[]\n",
        "for i in df_train['text']:\n",
        "  text = re.sub(r\"\\S*https?:\\S*\", \"\", i) \n",
        "  text = re.sub('[.,-]','',text)\n",
        "  text = re.sub(r\"[\\([{})|:*!?\\]]\", \"\", text)\n",
        "  text = re.sub(r\"[\\/'';\" \"\\]]\", \" \", text)\n",
        "  text = decontracted(text)\n",
        "  text = text.replace(\"‚Äôs\", \"\")\n",
        "  text = text.replace(\"¬Æ\", \"\")\n",
        "  text = text.replace(\"New article:\", \"\")\n",
        "  text = text.replace(\"new\", \"\")\n",
        "  text = text.replace(\"Link:\", \"\")\n",
        "  text=re.sub(\"[\\\"\\']\", \"\", text)\n",
        "  text=re.sub(\"[\\\\n\\']\", \"\", text)\n",
        "  # remove foreign launguage tweets\n",
        "  res = [idx for idx in text if not re.findall(\"[^\\u0000-\\u05C0\\u2100-\\u214F]+\", idx)]\n",
        "  text=''.join(res)\n",
        "  text=re.sub(\"[\\\\n\\']\", \"\", text)\n",
        "  text = decontracted(text)\n",
        "  text=text.strip()\n",
        "  text=re.sub(r'[0-9]+', '', text)\n",
        "  processed_tweets.append(text.lower())\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dtfvwZ6gb10w"
      },
      "outputs": [],
      "source": [
        "df_train['text']=processed_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbBel-1t71Mq",
        "outputId": "daf9c3a0-5f4b-40cc-8c42-c3227c7cc186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sequence length:  53\n"
          ]
        }
      ],
      "source": [
        "# get max word length from gievn tweets\n",
        "max_len_general_tweets= 0\n",
        "\n",
        "for tweet in df_train['text']:\n",
        "    input_ids = tokenizer.encode(tweet)\n",
        "    max_len_general_tweets= max(max_len_general_tweets, len(input_ids))       \n",
        "\n",
        "\n",
        "print('Max sequence length: ', max_len_general_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zQEHHag69SWw"
      },
      "outputs": [],
      "source": [
        "# padding and tokenizing the data\n",
        "bert_output_embedding=[]\n",
        "for tweet in df_train['text']:\n",
        "  encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 53,           \n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'tf',     \n",
        "                   )\n",
        "  output = model(encoded_tweet)\n",
        "  hidden_states = output[1]\n",
        "  embedding_output = hidden_states[0]\n",
        "  attention_hidden_states = hidden_states[1:4]\n",
        "  embedding=embedding_output[0,0,:]\n",
        "  temp=[]\n",
        "  for i in range(3):\n",
        "    temp.append(attention_hidden_states[i][0,0,:])\n",
        "  tensor=tf.concat([temp[2],temp[1],temp[0],embedding],axis=0)\n",
        "  bert_output_embedding.append(tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCyZWbN2EuDR",
        "outputId": "93f0b4d2-21e3-4b97-c8c0-901f0a1d4178"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(31329, 3072)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls_token_value=np.array(bert_output_embedding)\n",
        "cls_token_value.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2WJx3i_nF__1"
      },
      "outputs": [],
      "source": [
        "y=[]\n",
        "for i in df_train['new_sentiment'].values:\n",
        "  if i=='negative':\n",
        "    y.append(0)\n",
        "  if i=='positive':\n",
        "    y.append(1)\n",
        "  if i=='neutral':\n",
        "    y.append(2)\n",
        "y=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "R9mhr2eK600b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(cls_token_value,y ,stratify=y, test_size=0.20,random_state=33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "shgv18PpCiw9"
      },
      "outputs": [],
      "source": [
        "# Clear any logs from previous runs\n",
        "! rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabDUyunCpma",
        "outputId": "d9ff10cf-2639-47b2-fa56-7a03438b07d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 3072)]            0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 384)               1180032   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 192)               73920     \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 192)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                12352     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,266,499\n",
            "Trainable params: 1,266,499\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#tensorboard callback\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "input_layer=Input(shape=(cls_token_value.shape[1],))\n",
        "dense1=Dense(384, activation='relu')(input_layer)\n",
        "dense2=Dense(192, activation='relu')(dense1)\n",
        "drop1=Dropout(0.2)(dense2)\n",
        "dense3=Dense(64, activation='sigmoid')(drop1)\n",
        "output_layer=Dense(3, activation='softmax')(dense3)\n",
        "model_nn= Model(inputs=[input_layer], outputs=output_layer)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model_nn.compile(optimizer=optimizer, loss='SparseCategoricalCrossentropy',metrics=['accuracy'])\n",
        "# summarize layers\n",
        "print(model_nn.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJOzvnTorMNY",
        "outputId": "1b90be0c-9aff-4639-efd6-dd21a035eac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "784/784 [==============================] - 3s 3ms/step - loss: 1.0890 - accuracy: 0.3986 - val_loss: 1.0681 - val_accuracy: 0.3881\n",
            "Epoch 2/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 1.0011 - accuracy: 0.4888 - val_loss: 0.9225 - val_accuracy: 0.5432\n",
            "Epoch 3/100\n",
            "784/784 [==============================] - 3s 3ms/step - loss: 0.9170 - accuracy: 0.5551 - val_loss: 0.8718 - val_accuracy: 0.6002\n",
            "Epoch 4/100\n",
            "784/784 [==============================] - 3s 4ms/step - loss: 0.8836 - accuracy: 0.5820 - val_loss: 0.8469 - val_accuracy: 0.6058\n",
            "Epoch 5/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8608 - accuracy: 0.5939 - val_loss: 0.8240 - val_accuracy: 0.6175\n",
            "Epoch 6/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8468 - accuracy: 0.6041 - val_loss: 0.8357 - val_accuracy: 0.6152\n",
            "Epoch 7/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8338 - accuracy: 0.6147 - val_loss: 0.8092 - val_accuracy: 0.6288\n",
            "Epoch 8/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8243 - accuracy: 0.6220 - val_loss: 0.7826 - val_accuracy: 0.6492\n",
            "Epoch 9/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8211 - accuracy: 0.6270 - val_loss: 0.8152 - val_accuracy: 0.6347\n",
            "Epoch 10/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8141 - accuracy: 0.6241 - val_loss: 0.7824 - val_accuracy: 0.6486\n",
            "Epoch 11/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.8049 - accuracy: 0.6314 - val_loss: 0.8012 - val_accuracy: 0.6379\n",
            "Epoch 12/100\n",
            "784/784 [==============================] - 3s 3ms/step - loss: 0.8090 - accuracy: 0.6299 - val_loss: 0.9059 - val_accuracy: 0.5736\n",
            "Epoch 13/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7994 - accuracy: 0.6384 - val_loss: 0.8361 - val_accuracy: 0.6195\n",
            "Epoch 14/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7946 - accuracy: 0.6401 - val_loss: 0.7662 - val_accuracy: 0.6613\n",
            "Epoch 15/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7895 - accuracy: 0.6456 - val_loss: 0.7762 - val_accuracy: 0.6491\n",
            "Epoch 16/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7905 - accuracy: 0.6449 - val_loss: 0.7817 - val_accuracy: 0.6444\n",
            "Epoch 17/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7875 - accuracy: 0.6415 - val_loss: 0.7616 - val_accuracy: 0.6588\n",
            "Epoch 18/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7826 - accuracy: 0.6484 - val_loss: 0.7554 - val_accuracy: 0.6649\n",
            "Epoch 19/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7847 - accuracy: 0.6443 - val_loss: 0.7885 - val_accuracy: 0.6425\n",
            "Epoch 20/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7814 - accuracy: 0.6515 - val_loss: 0.8016 - val_accuracy: 0.6328\n",
            "Epoch 21/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7788 - accuracy: 0.6496 - val_loss: 0.9219 - val_accuracy: 0.6021\n",
            "Epoch 22/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7808 - accuracy: 0.6470 - val_loss: 0.8046 - val_accuracy: 0.6422\n",
            "Epoch 23/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7763 - accuracy: 0.6530 - val_loss: 0.7533 - val_accuracy: 0.6644\n",
            "Epoch 24/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7728 - accuracy: 0.6523 - val_loss: 0.7755 - val_accuracy: 0.6580\n",
            "Epoch 25/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7665 - accuracy: 0.6567 - val_loss: 0.7724 - val_accuracy: 0.6513\n",
            "Epoch 26/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7686 - accuracy: 0.6553 - val_loss: 0.7849 - val_accuracy: 0.6546\n",
            "Epoch 27/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7697 - accuracy: 0.6557 - val_loss: 0.8432 - val_accuracy: 0.6266\n",
            "Epoch 28/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7700 - accuracy: 0.6530 - val_loss: 0.7503 - val_accuracy: 0.6703\n",
            "Epoch 29/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7636 - accuracy: 0.6562 - val_loss: 0.7527 - val_accuracy: 0.6653\n",
            "Epoch 30/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7640 - accuracy: 0.6585 - val_loss: 0.7525 - val_accuracy: 0.6684\n",
            "Epoch 31/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7625 - accuracy: 0.6588 - val_loss: 0.8247 - val_accuracy: 0.6294\n",
            "Epoch 32/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7607 - accuracy: 0.6594 - val_loss: 0.7402 - val_accuracy: 0.6720\n",
            "Epoch 33/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7596 - accuracy: 0.6604 - val_loss: 0.7862 - val_accuracy: 0.6499\n",
            "Epoch 34/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7542 - accuracy: 0.6612 - val_loss: 0.7635 - val_accuracy: 0.6590\n",
            "Epoch 35/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7567 - accuracy: 0.6636 - val_loss: 0.7451 - val_accuracy: 0.6676\n",
            "Epoch 36/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7519 - accuracy: 0.6637 - val_loss: 0.8192 - val_accuracy: 0.6282\n",
            "Epoch 37/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7557 - accuracy: 0.6624 - val_loss: 0.7879 - val_accuracy: 0.6331\n",
            "Epoch 38/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7594 - accuracy: 0.6593 - val_loss: 0.7500 - val_accuracy: 0.6701\n",
            "Epoch 39/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7586 - accuracy: 0.6605 - val_loss: 0.7875 - val_accuracy: 0.6537\n",
            "Epoch 40/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7524 - accuracy: 0.6646 - val_loss: 0.7485 - val_accuracy: 0.6763\n",
            "Epoch 41/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7499 - accuracy: 0.6649 - val_loss: 0.7501 - val_accuracy: 0.6677\n",
            "Epoch 42/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7449 - accuracy: 0.6670 - val_loss: 0.7784 - val_accuracy: 0.6471\n",
            "Epoch 43/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7484 - accuracy: 0.6638 - val_loss: 0.7522 - val_accuracy: 0.6645\n",
            "Epoch 44/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7428 - accuracy: 0.6687 - val_loss: 0.7610 - val_accuracy: 0.6492\n",
            "Epoch 45/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7427 - accuracy: 0.6693 - val_loss: 0.7468 - val_accuracy: 0.6685\n",
            "Epoch 46/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7478 - accuracy: 0.6673 - val_loss: 0.7462 - val_accuracy: 0.6701\n",
            "Epoch 47/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7406 - accuracy: 0.6706 - val_loss: 0.8357 - val_accuracy: 0.6336\n",
            "Epoch 48/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7381 - accuracy: 0.6691 - val_loss: 0.7381 - val_accuracy: 0.6773\n",
            "Epoch 49/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7412 - accuracy: 0.6682 - val_loss: 0.8020 - val_accuracy: 0.6376\n",
            "Epoch 50/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7430 - accuracy: 0.6681 - val_loss: 0.7642 - val_accuracy: 0.6586\n",
            "Epoch 51/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7407 - accuracy: 0.6700 - val_loss: 0.7653 - val_accuracy: 0.6605\n",
            "Epoch 52/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7374 - accuracy: 0.6709 - val_loss: 0.7448 - val_accuracy: 0.6684\n",
            "Epoch 53/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7433 - accuracy: 0.6680 - val_loss: 0.7316 - val_accuracy: 0.6797\n",
            "Epoch 54/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7356 - accuracy: 0.6707 - val_loss: 0.7961 - val_accuracy: 0.6492\n",
            "Epoch 55/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7343 - accuracy: 0.6746 - val_loss: 0.7397 - val_accuracy: 0.6688\n",
            "Epoch 56/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7352 - accuracy: 0.6700 - val_loss: 0.7852 - val_accuracy: 0.6404\n",
            "Epoch 57/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7276 - accuracy: 0.6747 - val_loss: 0.7756 - val_accuracy: 0.6567\n",
            "Epoch 58/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7399 - accuracy: 0.6681 - val_loss: 0.7445 - val_accuracy: 0.6719\n",
            "Epoch 59/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7337 - accuracy: 0.6750 - val_loss: 0.7357 - val_accuracy: 0.6743\n",
            "Epoch 60/100\n",
            "784/784 [==============================] - 3s 4ms/step - loss: 0.7301 - accuracy: 0.6758 - val_loss: 0.7268 - val_accuracy: 0.6818\n",
            "Epoch 61/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7314 - accuracy: 0.6755 - val_loss: 0.7529 - val_accuracy: 0.6657\n",
            "Epoch 62/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7292 - accuracy: 0.6767 - val_loss: 0.7548 - val_accuracy: 0.6607\n",
            "Epoch 63/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7278 - accuracy: 0.6739 - val_loss: 0.7258 - val_accuracy: 0.6805\n",
            "Epoch 64/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7248 - accuracy: 0.6764 - val_loss: 0.7961 - val_accuracy: 0.6355\n",
            "Epoch 65/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7217 - accuracy: 0.6785 - val_loss: 0.7706 - val_accuracy: 0.6483\n",
            "Epoch 66/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7279 - accuracy: 0.6720 - val_loss: 0.7556 - val_accuracy: 0.6593\n",
            "Epoch 67/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7287 - accuracy: 0.6747 - val_loss: 0.7252 - val_accuracy: 0.6869\n",
            "Epoch 68/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7266 - accuracy: 0.6749 - val_loss: 0.8600 - val_accuracy: 0.6168\n",
            "Epoch 69/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7248 - accuracy: 0.6752 - val_loss: 0.7268 - val_accuracy: 0.6778\n",
            "Epoch 70/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7218 - accuracy: 0.6782 - val_loss: 0.7301 - val_accuracy: 0.6783\n",
            "Epoch 71/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7243 - accuracy: 0.6756 - val_loss: 0.7415 - val_accuracy: 0.6717\n",
            "Epoch 72/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7206 - accuracy: 0.6775 - val_loss: 0.8496 - val_accuracy: 0.6341\n",
            "Epoch 73/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7220 - accuracy: 0.6819 - val_loss: 0.7625 - val_accuracy: 0.6649\n",
            "Epoch 74/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7206 - accuracy: 0.6777 - val_loss: 0.7395 - val_accuracy: 0.6763\n",
            "Epoch 75/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7115 - accuracy: 0.6828 - val_loss: 0.7333 - val_accuracy: 0.6760\n",
            "Epoch 76/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7224 - accuracy: 0.6742 - val_loss: 0.7476 - val_accuracy: 0.6680\n",
            "Epoch 77/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7190 - accuracy: 0.6800 - val_loss: 0.7373 - val_accuracy: 0.6696\n",
            "Epoch 78/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7164 - accuracy: 0.6815 - val_loss: 0.7424 - val_accuracy: 0.6690\n",
            "Epoch 79/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7160 - accuracy: 0.6805 - val_loss: 0.7268 - val_accuracy: 0.6811\n",
            "Epoch 80/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7186 - accuracy: 0.6806 - val_loss: 0.7348 - val_accuracy: 0.6811\n",
            "Epoch 81/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7157 - accuracy: 0.6821 - val_loss: 0.7386 - val_accuracy: 0.6783\n",
            "Epoch 82/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7104 - accuracy: 0.6856 - val_loss: 0.7594 - val_accuracy: 0.6604\n",
            "Epoch 83/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7107 - accuracy: 0.6845 - val_loss: 0.7421 - val_accuracy: 0.6677\n",
            "Epoch 84/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7167 - accuracy: 0.6822 - val_loss: 0.7403 - val_accuracy: 0.6730\n",
            "Epoch 85/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7133 - accuracy: 0.6816 - val_loss: 0.7288 - val_accuracy: 0.6784\n",
            "Epoch 86/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7130 - accuracy: 0.6822 - val_loss: 0.7277 - val_accuracy: 0.6781\n",
            "Epoch 87/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7149 - accuracy: 0.6816 - val_loss: 0.7391 - val_accuracy: 0.6795\n",
            "Epoch 88/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7151 - accuracy: 0.6802 - val_loss: 0.7694 - val_accuracy: 0.6594\n",
            "Epoch 89/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7063 - accuracy: 0.6836 - val_loss: 0.7680 - val_accuracy: 0.6583\n",
            "Epoch 90/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7071 - accuracy: 0.6850 - val_loss: 0.7174 - val_accuracy: 0.6838\n",
            "Epoch 91/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7076 - accuracy: 0.6862 - val_loss: 0.7436 - val_accuracy: 0.6735\n",
            "Epoch 92/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7092 - accuracy: 0.6841 - val_loss: 0.7286 - val_accuracy: 0.6728\n",
            "Epoch 93/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7029 - accuracy: 0.6887 - val_loss: 0.7291 - val_accuracy: 0.6792\n",
            "Epoch 94/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7063 - accuracy: 0.6854 - val_loss: 0.7351 - val_accuracy: 0.6717\n",
            "Epoch 95/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7037 - accuracy: 0.6865 - val_loss: 0.7347 - val_accuracy: 0.6834\n",
            "Epoch 96/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7078 - accuracy: 0.6858 - val_loss: 0.7301 - val_accuracy: 0.6784\n",
            "Epoch 97/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7030 - accuracy: 0.6868 - val_loss: 0.7282 - val_accuracy: 0.6832\n",
            "Epoch 98/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7046 - accuracy: 0.6860 - val_loss: 0.7270 - val_accuracy: 0.6835\n",
            "Epoch 99/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7061 - accuracy: 0.6859 - val_loss: 0.7382 - val_accuracy: 0.6789\n",
            "Epoch 100/100\n",
            "784/784 [==============================] - 2s 3ms/step - loss: 0.7025 - accuracy: 0.6873 - val_loss: 0.7924 - val_accuracy: 0.6569\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f05b013a650>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_nn.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),callbacks=tensorboard_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis on tweet.json data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR2X3MaGHxdt",
        "outputId": "211403ec-f56b-4a4d-96ae-fb0efcb71daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sequence length:  28\n"
          ]
        }
      ],
      "source": [
        "max_len_tweets= 0\n",
        "\n",
        "for tweet in data_df['tweet_text']:\n",
        "    input_ids = tokenizer.encode(tweet)\n",
        "    max_len_general_tweets= max(max_len_tweets, len(input_ids))       \n",
        "\n",
        "\n",
        "print('Max sequence length: ', max_len_general_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "iPFguykLIKKp"
      },
      "outputs": [],
      "source": [
        "bert_output_embedding=[]\n",
        "for tweet in data_df['tweet_text']:\n",
        "  encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 28,           \n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'tf',     \n",
        "                   )\n",
        "  output = model(encoded_tweet)\n",
        "  hidden_states = output[1]\n",
        "  embedding_output = hidden_states[0]\n",
        "  attention_hidden_states = hidden_states[1:4]\n",
        "  embedding=embedding_output[0,0,:]\n",
        "  temp=[]\n",
        "  for i in range(3):\n",
        "    temp.append(attention_hidden_states[i][0,0,:])\n",
        "  tensor=tf.concat([temp[2],temp[1],temp[0],embedding],axis=0)\n",
        "  bert_output_embedding.append(tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DJSAFK6JJDS",
        "outputId": "97f1de70-bb45-4105-fbe6-79cb66bb0809"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43347, 3072)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls_token_value=np.array(bert_output_embedding)\n",
        "cls_token_value.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "dMLdDk3mJohj"
      },
      "outputs": [],
      "source": [
        "y_pred=model_nn.predict(cls_token_value)\n",
        "objective2=np.argmax(y_pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "eKl2jDSdX54f"
      },
      "outputs": [],
      "source": [
        "sentiment=[]\n",
        "for i in objective2:\n",
        "  if i==0:\n",
        "    sentiment.append('negative')\n",
        "  elif i==1:\n",
        "    sentiment.append('positive')\n",
        "  elif i==2:\n",
        "    sentiment.append('neutral')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "PvfnNiMFZdpq"
      },
      "outputs": [],
      "source": [
        "data_df['sentiment']=sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "_4snCgXiZozS",
        "outputId": "b297d07a-2163-41f6-d483-4a37a0437609"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6da712bf-3f5c-4221-9472-dda24d2ac985\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_ID</th>\n",
              "      <th>tweet_author</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1374140386071961602</td>\n",
              "      <td>Hematopoiesis News</td>\n",
              "      <td>Scientists conducted a Phase II study of acala...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1374032432173842437</td>\n",
              "      <td>Michael Wang, MD</td>\n",
              "      <td>This phase  AcalabrutinibVenetoclax AV trial t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1373902876553048065</td>\n",
              "      <td>1stOncology</td>\n",
              "      <td>#NICE backs #AstraZenecas #Calquence for #CLL</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1373656782367813635</td>\n",
              "      <td>Toby Eyre</td>\n",
              "      <td>#acalabrutinib is a valuable option in pts int...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1372941634334232586</td>\n",
              "      <td>Lymphoma Hub</td>\n",
              "      <td>NICE has recommended the use of acalabrutinib ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da712bf-3f5c-4221-9472-dda24d2ac985')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6da712bf-3f5c-4221-9472-dda24d2ac985 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6da712bf-3f5c-4221-9472-dda24d2ac985');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              tweet_ID        tweet_author  \\\n",
              "0  1374140386071961602  Hematopoiesis News   \n",
              "1  1374032432173842437    Michael Wang, MD   \n",
              "2  1373902876553048065         1stOncology   \n",
              "3  1373656782367813635           Toby Eyre   \n",
              "4  1372941634334232586        Lymphoma Hub   \n",
              "\n",
              "                                          tweet_text sentiment  \n",
              "0  Scientists conducted a Phase II study of acala...   neutral  \n",
              "1  This phase  AcalabrutinibVenetoclax AV trial t...   neutral  \n",
              "2      #NICE backs #AstraZenecas #Calquence for #CLL   neutral  \n",
              "3  #acalabrutinib is a valuable option in pts int...   neutral  \n",
              "4  NICE has recommended the use of acalabrutinib ...  positive  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "objective1.to_csv('objective1.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "sSNA4X-E-sHf"
      },
      "outputs": [],
      "source": [
        "data_temp=data_df[['tweet_author','tweet_text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "PB2fwiuW8Hjg"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "fVf-5yex8Ipx"
      },
      "outputs": [],
      "source": [
        "tweet_author=[]\n",
        "entity=[]\n",
        "for row in data_temp.values:\n",
        "  author=row[0]\n",
        "  textt=row[1]\n",
        "  sen = sp(textt)\n",
        "  entities=sen.ents\n",
        "  tweet_author.append(author)\n",
        "  if len(entities)==1:\n",
        "    entity.append(entities[0].text)\n",
        "  elif len(entities)>1:\n",
        "    string=entities[0].text\n",
        "    for i in range(1,len(entities)):\n",
        "      string=string+'_'+entities[i].text\n",
        "    entity.append(string)\n",
        "  else:\n",
        "     entity.append(entities)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4HWitotAhdz",
        "outputId": "76bee611-9c85-449f-ad4d-e8522fb4528e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "objective2=pd.DataFrame({'entity':np.array(entity),'tweet_author':np.array(tweet_author),'sentiment':data_df['sentiment'].values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "P6nCV9C0JlUE"
      },
      "outputs": [],
      "source": [
        "objective2.to_csv('objective2.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF_lHbqg7C1Y"
      },
      "source": [
        "## Observations\n",
        "1) considering bert final hidden state embedding only \n",
        "have high training accuracy but validation accuracy is 0.9 and 0.74<br>\n",
        "2) considering bert final hidden state and last 3 hiddne sate outputs and concatenate them to get final embedding vector have  training accuracy and validation accuracy is close to 0.84 and 0.81<br>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ffc07624923affceafa6fae0f78aaad727ebda5598769363d4c8d76f29989191"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
